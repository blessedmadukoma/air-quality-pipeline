{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(\"INSTALL httpfs; LOAD httpfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect or Create a database\n",
    "conn = duckdb.connect(\"../air_quality.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7760ce1c6d70>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conn.execute(\"DROP schema IF EXISTS raw CASCADE\")\n",
    "conn.execute(\"CREATE schema IF NOT EXISTS raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAQ's S3 bucket is public, \n",
    "# however, \n",
    "# DuckDB requires access and secret keys, \n",
    "# therefore, \n",
    "# set to blank\n",
    "\n",
    "conn.sql(\"\"\"\n",
    "SET s3_access_key_id='';\n",
    "SET s3_secret_access_key='';\n",
    "SET s3_region='';\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7760ce1c6d70>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a raw table in the database to store the data coming from the S3 bucket (the column names in double quotes are keywords in DuckDB)\n",
    "conn.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS raw.air_quality_data (\n",
    "        location_id BIGINT,\n",
    "        sensors_id BIGINT,\n",
    "        \"location\" VARCHAR,\n",
    "        \"datetime\" TIMESTAMP,\n",
    "        lat DOUBLE,\n",
    "        lon DOUBLE,\n",
    "        \"parameter\" VARCHAR,\n",
    "        units VARCHAR,\n",
    "        \"value\" DOUBLE,\n",
    "        \"month\" VARCHAR,\n",
    "        \"year\" BIGINT,\n",
    "        ingestion_datetime TIMESTAMP\n",
    "    );\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd642b7736c40fd9fe3c098e826cd38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# insert the data from OpenAQ's s3 bucket\n",
    "\n",
    "# s3_bucket = 's3://openaq-data-archive/records/csv.gz/locationid=42400/year=2023/month=01/*.csv.gz'\n",
    "s3_bucket = 's3://openaq-data-archive/records/csv.gz/locationid=225393/year=2024/month=01/*.csv.gz'\n",
    "\n",
    "try:\n",
    "    conn.execute(f\"\"\"\n",
    "        INSERT INTO raw.air_quality_data\n",
    "        SELECT\n",
    "                 location_id,\n",
    "                 sensors_id,\n",
    "                 \"location\",\n",
    "                 \"datetime\",\n",
    "                 lat,\n",
    "                 lon,\n",
    "                 \"parameter\",\n",
    "                 units,\n",
    "                 \"value\",\n",
    "                 \"month\",\n",
    "                 \"year\",\n",
    "                 current_timestamp AS ingestion_datetime\n",
    "        FROM read_csv('{s3_bucket}')\n",
    "    \"\"\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   count_star()\n",
      "0          3278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213151/4287083592.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(\"SELECT COUNT(*) FROM raw.air_quality_data;\", con=conn)\n"
     ]
    }
   ],
   "source": [
    "# check the content of the database using pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Query the database using the existing connection\n",
    "df = pd.read_sql_query(\"SELECT COUNT(*) FROM raw.air_quality_data;\", con=conn)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the connection\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
